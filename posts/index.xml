<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 首页</title>
    <link>https://candoeverything.github.io/posts/</link>
    <description>Recent content in Posts on 首页</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zk-CN</language>
    <lastBuildDate>Sun, 21 Jul 2019 20:38:41 +0800</lastBuildDate>
    
	<atom:link href="https://candoeverything.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Flume异常：ERROR PollableSourceRunner-kafkaSource-r1 process failed java.lang.OutOfMemoryError GC overhead limit exceeded</title>
      <link>https://candoeverything.github.io/2019/flume_outofmemory/</link>
      <pubDate>Sun, 21 Jul 2019 20:38:41 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/flume_outofmemory/</guid>
      <description>使用Flume的时候抛出：ERROR PollableSourceRunner-kafkaSource-r1 process failed java.lang.OutOfMemoryError GC overhead limit exceeded
原因： 抛出如上异常，是因为Flume内存溢出，没有足够的内存继续运行。  解决方案： 到$flume/conf/flume-env.sh目录下，添加一下配置 export JAVA_OPTS=&amp;quot;-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote&amp;quot;  根据自己的节点配置，来调整。-Xmx与-Xms最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc。</description>
    </item>
    
    <item>
      <title>Flume配置的roll不生效问题</title>
      <link>https://candoeverything.github.io/2019/flume_rollerror/</link>
      <pubDate>Sun, 21 Jul 2019 20:34:09 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/flume_rollerror/</guid>
      <description>当我们使用hdfsSink的时候，我们往往会要求文件以时间，文件大小或者数据条数滚动，以避免参数小文件。
 a1.sinks.k1.type=hdfs a1.sinks.k1.hdfs.path=/temp/%Y-%m-%d a1.sinks.k1.hdfs.round=true a1.sinks.k1.hdfs.roundvalue=1 a1.sinks.k1.hdfs.roundUnit=hour a1.sinks.k1.hdfs.rollCount=0 //设置不以条数滚动 a1.sinks.k1.hdfs.rollInterval=0 //设置不以时间滚动 a1.sinks.k1.hdfs.rollSize =134217728 //文件达到128M滚动一次
 当我执行以上脚本的时候，发现并没有和我想象的那一样以128m滚动一次文件。而是1秒内滚动一次，产生大量的小文件。
滚动属性为什么不生效？ 我查了资料才发现，当你设置的副本数（hdfs.minBolckReplicas）设置不为1的时候， 你的roll文件的配置就不会生效。  解决方法 添加 a1.sinks.k1.hdfshdfs.minBolckReplicas=1 即可  为什么hdfshdfs.minBolckReplicas会影响roll文件滚动呢？ 假如hdfs的副本是3，flume配置滚动时间为10s，那么在第二秒的时候，flume就会检测到hdfs在复制块，那么这个时候flume为了不影响hdfs复制块的过程，就会滚动文件。 这样就会导致我们设置的roll配置不生效。 k1.hdfshdfs.minBolckReplicas=1就是为了防flume感知不到hdfs的快复制，这样roll配置就不会受到影响。</description>
    </item>
    
    <item>
      <title>数据仓库分层简单阐述</title>
      <link>https://candoeverything.github.io/2019/datawarehouse/</link>
      <pubDate>Fri, 19 Jul 2019 14:44:26 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/datawarehouse/</guid>
      <description>  数据仓库的概念 数据仓库分层 数据仓库每层的阐述 数据仓库分层的作用  数据仓库的概念 数据仓库是面向企业级的，为企业的每个部门提供决策手段。
数据仓库的分层 在一般的的企业中，数据仓库一般分为4个层次。即ODS（Operation Data Store 数据原始层），DWD（Data Warehouse Detail 明细数据层），DWS（Dara Warehouse Service 数据服务层），ADS（application Data Store 数据应用层）。 不同企业可能分的层次不一样。也有可能每个层次的命名不一样，因为没有统一的命名规则，但是每层的功能都是一样的。   ODS：存储数据最原始的数据，数据不得任何处理，一定要原封不动。 DWD：对数据数据进行ETL处理，该层结构和粒度与ODS保持一致。 DWS：在DWD的基础上，对数据进行汇总处理。 ADS：为报表提供数据。  数据仓库分层的作用  隔离原始数据。原始数据单层存储，不守其他层次操作的影响。 减少重复处理。既然每一层都有相对于的功能，处理某个功能只要到相对于的层开发即可。不需要第一层开始到最后一层。  </description>
    </item>
    
    <item>
      <title>MySQL异常：You can&#39;t specify target table for update in FROM clause解决办法</title>
      <link>https://candoeverything.github.io/2019/mysql_exce2/</link>
      <pubDate>Thu, 18 Jul 2019 12:18:16 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/mysql_exce2/</guid>
      <description> 原因 在同一张表中，不能先select某个字段的值，再进行update这个字段的字。 例如：delete from person where id =(select max(id) from Person a group by email having count(email)&amp;gt;=2) ; 这条sql语句，先查询where 条件后面的子查询 id，然后在进行delete这个id，所以报错！！  解决方法： 可以通过中间表消除。 delete from person where id =(select * from (select max(id) from Person a group by email having count(email)&amp;gt;=2) a); 将子查询通过中间表包装起来即可。  </description>
    </item>
    
    <item>
      <title>Mysql异常报错:This version of MySQL doesn&#39;t yet support &#39;LIMIT &amp; IN/ALL/ANY/SOME subquery</title>
      <link>https://candoeverything.github.io/2019/mysql_exce1/</link>
      <pubDate>Thu, 18 Jul 2019 12:01:51 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/mysql_exce1/</guid>
      <description>This version of MySQL doesn&amp;rsquo;t yet support &amp;lsquo;LIMIT &amp;amp; IN/ALL/ANY/SOME subquery select d.name Department ,e.name Employee,Salary from Employee e join Department d on e.DepartmentId=d.id where e.id=(select id from Employee order by Salary limit 3); 我在求一道求工资前三的员工的信息及其所属的部门的时候，这是我写的sql语句。执行的时候却抛出异常This version of MySQL doesn&#39;t yet support &#39;LIMIT &amp;amp; IN/ALL/ANY/SOME subquery。  原因 从字面上来看，这个版本的mysql不支持limit和IN/ALL/ANY/SOME同时存在。简单来说就是子查询的时候IN/ALL/ANY/SOME和limit不能直接的搭配使用。  解决方法 可以将通过中间表将带有limit的sql语句 [select id from (select id from Employee order by Salary limit 3) tmp ]包装起来，这样就能正常运行了。 select d.name Department ,e.name Employee,Salary from Employee e join Department d on e.</description>
    </item>
    
    <item>
      <title>更新本地代码上传带git</title>
      <link>https://candoeverything.github.io/2019/upload/</link>
      <pubDate>Wed, 17 Jul 2019 22:54:09 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/upload/</guid>
      <description>//新建一个文件 hugo new post/upload.md
//更新本地代码以远端仓库一致 hugo &amp;ndash;theme=LeaveIt &amp;ndash;baseUrl=&amp;ldquo;https://candoeverything.github.io/&amp;quot; &amp;ndash;buildDrafts cd public git add . git commit -m &amp;ldquo;XXXXXXX&amp;rdquo; git pull origin master git push origin master</description>
    </item>
    
    <item>
      <title>Flume简单概述</title>
      <link>https://candoeverything.github.io/2019/blog/</link>
      <pubDate>Wed, 17 Jul 2019 12:47:15 +0800</pubDate>
      
      <guid>https://candoeverything.github.io/2019/blog/</guid>
      <description> 1.Flume的概念 2.Flume的作用和用途 3.Flume的组成架构 4.Flume的事务 1.1 什么是Flume？ 定义：Flume是一个高可用，分布式的海量日志采集系统。  2.1Flume的的作用是什么？ Flume的作用：实时的监控某个某个文件夹或者文件内数据的变化，然后再将变化的数据传输到目的源存储或者分析处理。  2.2Flume的企业中主要用途  实时的读取服务器产生的日志数据或者爬虫爬爬取的数据，然后传输到指定目的源处理。 一般flume下端都会与kafka搭配，这样可以指定数据到多个目的地。（例如数据传输到hdfs进行备份，同时也传输给spark进行实时的分析数据等等。。）  3.1Flume的组成架构 Flume的工作基本单元是Agent，agent是一个jvm进程，它是将数据包装成事件event从数据源传输到目的源。 Agent有三个组件组成： 1.Source：从数据源拉取数据，通过put事务将数据传输给channel。 2.Channel：作为Source和Sink的数据的缓存区。 3.Sink：拉取缓存在channel的数据，然后传输给下一个目的源。  4.1Flume的事务 Put事务 putlist：是一个临时缓冲区，用于缓存数据。 doPut：将数据缓存到临时缓存区putlist。 doCommit：检查channel内存是否足够。若是足够，将数据写入到channel。若是不够，则执行dorollback。 doRollBack：当channel内存不够时候，将数据回滚，保证了数据安全性。  Take事务 takelist：是一个临时缓冲区，用于缓存数据。 doTake：将channel的数据缓存到临时缓冲区takelist，并删掉channel内的数据。 doCommit：检查数据是否全部成功传输到下一个目的源。若全部传输成功，则删除掉takelist缓存的数据。 doRollBack：若是传输过程中出现故障，数据没能全部传输成功，则将takelist内的数据回滚给channel。  </description>
    </item>
    
  </channel>
</rss>